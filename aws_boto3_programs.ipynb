{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "@Author: Vighnesh Harish Bilgi\n",
    "@Date: 2022-11-02\n",
    "@Last Modified by: Vighnesh Harish Bilgi\n",
    "@Last Modified time: 2022-11-02\n",
    "@Title : AWS BOTO3 programs\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'ap-south-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('test1_access_key')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('test1_secret_access_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Uploading different file formats to S3 Bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Upload CSV File to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    df = pd.read_csv('sampleFiles/iris-dataset.csv')\n",
    "\n",
    "    client.upload_file(Filename = 'sampleFiles/iris-dataset.csv',Bucket = 'transfer-to-s3', Key = 'iris-dataset.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Upload TXT File to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource('s3')\n",
    "    # client = boto3.client(\"s3\")\n",
    "    return s3\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    # client.upload_file(Filename = 'sampleFiles/sampleText.txt',Bucket = 'transfer-to-s3', Key = 'sampleText.txt')\n",
    "    s3.Bucket('transfer-to-s3').upload_file(Filename = 'sampleFiles/sampleText.txt', Key = 'sampleText.txt')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Upload JSON File to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    df = pd.read_json('sampleFiles/sampleJSON.json')\n",
    "\n",
    "    client.upload_file(Filename = 'sampleFiles/sampleJSON.json',Bucket = 'transfer-to-s3', Key = 'sampleJSON.json')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Upload PNG File to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    client.upload_file(Filename = 'sampleFiles/aws.png',Bucket = 'transfer-to-s3', Key = 'aws.png')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Download Files from AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Load and Download CSV file from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    # obj = s3.Bucket('transfer-to-s3').Object('sampleCSV2.csv').get()\n",
    "    obj = client.get_object(Bucket='transfer-to-s3', Key='sampleCSV2.csv')\n",
    "\n",
    "    df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    print(df.head(5))\n",
    "\n",
    "    # s3.Bucket('transfer-to-s3').download_file(Key = 'sampleCSV2.csv', Filename = 'sampleFiles/sampleCSV2.csv')\n",
    "    client.download_file('transfer-to-s3', 'sampleCSV2.csv', 'sampleFiles/sampleCSV2.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Load and Download TXT file from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    obj = client.get_object(Bucket='transfer-to-s3', Key='sampleText2.txt')\n",
    "\n",
    "    text_file = obj['Body'].read().decode(encoding=\"utf-8\",errors=\"ignore\")\n",
    "    print(text_file)\n",
    "\n",
    "    client.download_file('transfer-to-s3', 'sampleText2.txt', 'sampleFiles/sampleText2.txt')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Load and Download JSON file from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    obj = client.get_object(Bucket='transfer-to-s3', Key='sampleJSON2.json')\n",
    "\n",
    "    df = pd.read_json(obj['Body'])\n",
    "    print(df.head(5))\n",
    "\n",
    "    client.download_file('transfer-to-s3', 'sampleJSON2.json', 'sampleFiles/sampleJSON2.json')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Load and Download PNG file from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    obj = client.get_object(Bucket='transfer-to-s3', Key='s3.png')\n",
    "\n",
    "    # img_file = obj['Body'].read()\n",
    "    # print(img_file)\n",
    "\n",
    "    client.download_file('transfer-to-s3', 's3.png', 'sampleFiles/s3.png')\n",
    "\n",
    "    img=mpimg.imread('sampleFiles/s3.png')\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show(imgplot)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload large file to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    df = pd.read_csv('sampleFiles/iris-dataset.csv')\n",
    "\n",
    "    #s3.Bucket('transfer-to-s3').upload_file(Filename = 'sampleFiles/ubuntu-20.04.iso', Key = 'ubuntu-20.04.iso')\n",
    "    client.upload_file(Filename = 'sampleFiles/ubuntu-20.04.iso',Bucket = 'transfer-to-s3', Key = 'ubuntu-20.04.iso')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CRUD operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boto3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 202\u001b[0m\n\u001b[1;32m    198\u001b[0m     delete_bucket(s3)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 202\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn [3], line 148\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m--> 148\u001b[0m     s3 \u001b[39m=\u001b[39m connect_to_s3()\n\u001b[1;32m    150\u001b[0m     \u001b[39m# CRUD operations\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m     \u001b[39m# 1. C : CREATE\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[39m# 1a. Create Bucket\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     create_bucket(s3)\n",
      "Cell \u001b[0;32mIn [3], line 11\u001b[0m, in \u001b[0;36mconnect_to_s3\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect_to_s3\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39m    Description:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m        ServiceResource s3\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     s3 \u001b[39m=\u001b[39m  boto3\u001b[39m.\u001b[39mresource(service_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39ms3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m s3\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boto3' is not defined"
     ]
    }
   ],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3')\n",
    "    return s3\n",
    "\n",
    "def upload_to_bucket(path,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        Create a csv out of a dataframe by taking file path of csv file (i.e. string 'path') and uploading it to AWS S3 bucket.\n",
    "    Parameter:\n",
    "        string path,\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    file_key = path.split('/')[1]\n",
    "    s3.Bucket('crud-bucket-demo').upload_file(Filename = path, Key = file_key)\n",
    "\n",
    "def create_bucket(s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "\n",
    "    s3.create_bucket(Bucket = 'crud-bucket-demo',  CreateBucketConfiguration={'LocationConstraint': 'ap-south-1'})\n",
    "    print(\"Printing all bucket names to verify if - crud-bucket-demo is created:\")\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "\n",
    "def read_bucket(s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "\n",
    "    for obj in s3.Bucket('crud-bucket-demo').objects.all():\n",
    "\n",
    "        print(obj.key)\n",
    "        csv_obj = s3.Bucket('crud-bucket-demo').Object(obj.key).get()\n",
    "        read_df = pd.read_csv(csv_obj['Body'], index_col=0)\n",
    "        print(read_df,\"\\n\")\n",
    "\n",
    "def add_column(obj,new_col,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    address_book_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    address_book_df['MobileNumber'] =  new_col\n",
    "    address_book_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'address_book_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    return address_book_df\n",
    "\n",
    "def add_row(obj,new_row,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    shop_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    shop_df = shop_df.append(new_row, ignore_index = True)\n",
    "    shop_df['ItemID'] = ['ITM001','ITM002','ITM003','ITM004']\n",
    "    shop_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'shop_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    return shop_df\n",
    "\n",
    "def change_value(obj,new_value,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    employee_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    employee_df['EmpID'] = new_value\n",
    "    employee_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'employee_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    return employee_df\n",
    "\n",
    "def delete_bucket(s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    s3.Bucket('crud-bucket-demo').objects.all().delete()\n",
    "    print('Reading each file from bucket : crud-bucket-demo')\n",
    "\n",
    "    for obj in s3.Bucket('crud-bucket-demo').objects.all():\n",
    "\n",
    "        print(obj.key)\n",
    "        csv_obj = s3.Bucket('crud-bucket-demo').Object(obj.key).get()\n",
    "        read_df = pd.read_csv(csv_obj['Body'], index_col=0)\n",
    "        print(read_df,\"\\n\")\n",
    "\n",
    "    # Delete bucket\n",
    "    s3.Bucket('crud-bucket-demo').delete()\n",
    "    print(\"Printing all bucket names to verify if - crud-bucket-demo is deleted:\")\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    # CRUD operations\n",
    "\n",
    "    # 1. C : CREATE\n",
    "    # 1a. Create Bucket\n",
    "    create_bucket(s3)\n",
    "\n",
    "    # 1b. Reading 3 csv files and loading them to the bucket\n",
    "\n",
    "    path = 'sampleFiles/address_book_csv.csv'\n",
    "    upload_to_bucket(path,s3)\n",
    "\n",
    "    path = 'sampleFiles/employee_csv.csv'\n",
    "    upload_to_bucket(path,s3)\n",
    "\n",
    "    path = 'sampleFiles/shop_csv.csv'\n",
    "    upload_to_bucket(path,s3)\n",
    "\n",
    "    # 2. R : READ\n",
    "    print('\\nReading each file from bucket : crud-bucket-demo')\n",
    "    read_bucket(s3)\n",
    "\n",
    "    # 3. U : UPDATE\n",
    "    # Updating csv files and loading them to bucket\n",
    "\n",
    "    print(\"Adding MobileNumber column to address_book_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('address_book_csv.csv').get()\n",
    "    mobNo = [9012783465,9763214580,8192037465]\n",
    "    new_df = add_column(obj,mobNo,s3)\n",
    "    print(new_df)\n",
    "\n",
    "    #Changing 'EMP003' to 'EMP004' in employee_df\n",
    "    print(\"Changing 'EMP003' to 'EMP004' in employee_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('employee_csv.csv').get()\n",
    "    new_value = ['EMP001','EMP002','EMP004']\n",
    "    new_df = change_value(obj,new_value,s3)\n",
    "    print(new_df)\n",
    "\n",
    "    # Adding new item to shop_df\n",
    "    print(\"Adding new item to shop_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('shop_csv.csv').get()\n",
    "    new_item_dict = {'ItemID':'ITM004', 'ProductName':'Sharpner', 'Price': 10}\n",
    "    new_df = add_row(obj,new_item_dict,s3)\n",
    "    print(new_df)\n",
    "\n",
    "    # 4. D : DELETE\n",
    "    # DELETE Bucket\n",
    "    # Remove all files/objects under bucket and deleting bucket\n",
    "\n",
    "    delete_bucket(s3)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create EC2 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Create EC2 instance on Amazon Linux AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_ec2_client():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS EC2 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource ec2\n",
    "    \"\"\"\n",
    "    ec2_client = boto3.client(\"ec2\")\n",
    "    return ec2_client\n",
    "\n",
    "def connect_to_ec2_resource():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS EC2 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource ec2\n",
    "    \"\"\"\n",
    "    ec2_resource = boto3.resource(\"ec2\")\n",
    "    return ec2_resource\n",
    "\n",
    "def main():\n",
    "\n",
    "    ec2_client = connect_to_ec2_client()\n",
    "\n",
    "    # print(ec2.describe_instances())\n",
    "\n",
    "    # Create Key pair\n",
    "    # kp = ec2.create_key_pair(KeyName = 'demo-keypair')\n",
    "    # print(kp)\n",
    "    # print(kp['KeyMaterial'])\n",
    "\n",
    "    # file = open('demo-keypair.pem','w')\n",
    "    # file.write(kp['KeyMaterial'])\n",
    "    # file.close()\n",
    "\n",
    "    #Create Security Group\n",
    "    # for k in ec2_client.describe_security_groups():\n",
    "    #     print(k, ec2_client.describe_security_groups()[k])\n",
    "\n",
    "    # sec_group = ec2.create_security_group(\n",
    "\n",
    "    #     GroupName = 'demo-keypair',\n",
    "    #     Description = 'demo-keypair sg',\n",
    "    #     VpcId = 'vpc-001007bd2573bdfad'\n",
    "    # )\n",
    "\n",
    "    # print(sec_group)\n",
    "\n",
    "    # gid = 'sg-036c850a304135a6b' #sec_group['GroupId'] #'sg-036c850a304135a6b'\n",
    "\n",
    "    # ec2_client.authorize_security_group_ingress(\n",
    "    #     GroupId = 'sg-036c850a304135a6b',\n",
    "    #     IpPermissions = [\n",
    "    #         {\n",
    "    #             'IpProtocol': 'tcp', \n",
    "    #             'FromPort': 80,\n",
    "    #             'ToPort' : 80,\n",
    "    #             'IpRanges' : [{'CidrIp': '0.0.0.0/0'}]\n",
    "    #         },\n",
    "    #         {\n",
    "    #             'IpProtocol': 'tcp', \n",
    "    #             'FromPort': 22,\n",
    "    #             'ToPort' : 22,\n",
    "    #             'IpRanges' : [{'CidrIp': '0.0.0.0/0'}]\n",
    "    #         }\n",
    "    #     ]        \n",
    "    # )\n",
    "\n",
    "    ec2_resource = connect_to_ec2_resource()\n",
    "\n",
    "    # instances = ec2_resource.create_instances(\n",
    "    #     ImageId = 'ami-0e6329e222e662a52',\n",
    "    #     MinCount = 1,\n",
    "    #     MaxCount = 1,\n",
    "    #     InstanceType = 't2.micro',\n",
    "    #     KeyName = 'demo-keypair',\n",
    "    #     BlockDeviceMappings = [\n",
    "    #         {\n",
    "    #             'DeviceName' : \"/dev/xvda\",\n",
    "    #             'Ebs': {\n",
    "    #                     'DeleteOnTermination': True,\n",
    "    #                     'VolumeSize': 20\n",
    "    #             }\n",
    "    #         }\n",
    "\n",
    "    #     ],\n",
    "    #     SecurityGroups = ['demo-keypair']\n",
    "    # )\n",
    "\n",
    "    #Stop Instance\n",
    "    # ec2_client.stop_instances(InstanceIds = ['i-0bee9fbbf2c9214ca'])\n",
    "    #Start Instance\n",
    "    ec2_client.start_instances(InstanceIds = ['i-0bee9fbbf2c9214ca'])\n",
    "    #Termintate Instance\n",
    "    # ec2_client.termintate_instances(InstanceIds = ['i-0bee9fbbf2c9214ca'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. EC2 Instance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
