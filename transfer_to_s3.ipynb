{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n@Author: Vighnesh Harish Bilgi\\n@Date: 2022-11-02\\n@Last Modified by: Vighnesh Harish Bilgi\\n@Last Modified time: 2022-11-02\\n@Title : Transfer files to CSV \\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "@Author: Vighnesh Harish Bilgi\n",
    "@Date: 2022-11-02\n",
    "@Last Modified by: Vighnesh Harish Bilgi\n",
    "@Last Modified time: 2022-11-02\n",
    "@Title : Transfer files to CSV \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'ap-south-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('test1_access_key')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('test1_secret_access_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Upload CSV File to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    df = pd.read_csv('sampleFiles/iris-dataset.csv')\n",
    "\n",
    "    client.upload_file(Filename = 'sampleFiles/iris-dataset.csv',Bucket = 'transfer-to-s3', Key = 'iris-dataset.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Download CSV file from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Industry_aggregation_NZSIOC Industry_code_NZSIOC Industry_name_NZSIOC  \\\n",
      "Year                                                                         \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "\n",
      "                   Units Variable_code  \\\n",
      "Year                                     \n",
      "2021  Dollars (millions)           H01   \n",
      "2021  Dollars (millions)           H04   \n",
      "2021  Dollars (millions)           H05   \n",
      "2021  Dollars (millions)           H07   \n",
      "2021  Dollars (millions)           H08   \n",
      "\n",
      "                                        Variable_name      Variable_category  \\\n",
      "Year                                                                           \n",
      "2021                                     Total income  Financial performance   \n",
      "2021  Sales, government funding, grants and subsidies  Financial performance   \n",
      "2021                Interest, dividends and donations  Financial performance   \n",
      "2021                             Non-operating income  Financial performance   \n",
      "2021                                Total expenditure  Financial performance   \n",
      "\n",
      "        Value                             Industry_code_ANZSIC06  \n",
      "Year                                                              \n",
      "2021  757,504  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021  674,890  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021   49,593  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021   33,020  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021  654,404  ANZSIC06 divisions A-S (excluding classes K633...  \n"
     ]
    }
   ],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    # obj = s3.Bucket('transfer-to-s3').Object('sampleCSV2.csv').get()\n",
    "    obj = client.get_object(Bucket='transfer-to-s3', Key='sampleCSV2.csv')\n",
    "\n",
    "    df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    print(df.head(5))\n",
    "\n",
    "    # s3.Bucket('transfer-to-s3').download_file(Key = 'sampleCSV2.csv', Filename = 'sampleFiles/sampleCSV2.csv')\n",
    "    client.download_file('transfer-to-s3', 'sampleCSV2.csv', 'sampleFiles/sampleCSV2.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload large file to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "def main():\n",
    "\n",
    "    client = connect_to_s3()\n",
    "\n",
    "    df = pd.read_csv('sampleFiles/iris-dataset.csv')\n",
    "\n",
    "    #s3.Bucket('transfer-to-s3').upload_file(Filename = 'sampleFiles/ubuntu-20.04.iso', Key = 'ubuntu-20.04.iso')\n",
    "    client.upload_file(Filename = 'sampleFiles/ubuntu-20.04.iso',Bucket = 'transfer-to-s3', Key = 'ubuntu-20.04.iso')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CRUD operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all bucket names to verify if - crud-bucket-demo is created:\n",
      "crud-bucket-demo\n",
      "mumbai-bucket-demo\n",
      "transfer-to-s3\n",
      "\n",
      "Reading each file from bucket : crud-bucket-demo\n",
      "address_book_csv.csv\n",
      "           Lastname       City        State     Zip      Address  \\\n",
      "Firstname                                                          \n",
      "Vighnesh      Bilgi       Pune  Maharashtra  411019  HDFC Colony   \n",
      "Anoop      Aparajit     Nagpur  Maharashtra  440036      Jaitala   \n",
      "Carl           Pais  Bengaluru    Bengaluru  671326   Whitefield   \n",
      "\n",
      "                       Email  \n",
      "Firstname                     \n",
      "Vighnesh   vhbilgi@gmail.com  \n",
      "Anoop           aa@yahoo.com  \n",
      "Carl             cvp@aol.com   \n",
      "\n",
      "employee_csv.csv\n",
      "       Firstname Lastname       Role       Dept       MobNo\n",
      "EmpID                                                      \n",
      "EMP001    George    Smith   DataEngg         IT  9049480396\n",
      "EMP002     Rahul    Kumar     SWEngg         IT  8220858443\n",
      "EMP003    Priyal    Nayak  SalesEngg  Marketing  9876543210 \n",
      "\n",
      "shop_csv.csv\n",
      "       ProductName  Price\n",
      "ItemID                   \n",
      "ITM001       Pepsi     25\n",
      "ITM002        Acer  70000\n",
      "ITM003       Chair    500 \n",
      "\n",
      "Adding MobileNumber column to address_book_df\n",
      "           Lastname       City        State     Zip      Address  \\\n",
      "Firstname                                                          \n",
      "Vighnesh      Bilgi       Pune  Maharashtra  411019  HDFC Colony   \n",
      "Anoop      Aparajit     Nagpur  Maharashtra  440036      Jaitala   \n",
      "Carl           Pais  Bengaluru    Bengaluru  671326   Whitefield   \n",
      "\n",
      "                       Email  MobileNumber  \n",
      "Firstname                                   \n",
      "Vighnesh   vhbilgi@gmail.com    9012783465  \n",
      "Anoop           aa@yahoo.com    9763214580  \n",
      "Carl             cvp@aol.com    8192037465  \n",
      "Changing 'EMP003' to 'EMP004' in employee_df\n",
      "       Firstname Lastname       Role       Dept       MobNo   EmpID\n",
      "EmpID                                                              \n",
      "EMP001    George    Smith   DataEngg         IT  9049480396  EMP001\n",
      "EMP002     Rahul    Kumar     SWEngg         IT  8220858443  EMP002\n",
      "EMP003    Priyal    Nayak  SalesEngg  Marketing  9876543210  EMP004\n",
      "Adding new item to shop_df\n",
      "  ProductName  Price  ItemID\n",
      "0       Pepsi     25  ITM001\n",
      "1        Acer  70000  ITM002\n",
      "2       Chair    500  ITM003\n",
      "3    Sharpner     10  ITM004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40144/1123282469.py:94: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  shop_df = shop_df.append(new_row, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading each file from bucket : crud-bucket-demo\n",
      "Printing all bucket names to verify if - crud-bucket-demo is deleted:\n",
      "mumbai-bucket-demo\n",
      "transfer-to-s3\n"
     ]
    }
   ],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3')\n",
    "    return s3\n",
    "\n",
    "def upload_to_bucket(path,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        Create a csv out of a dataframe by taking file path of csv file (i.e. string 'path') and uploading it to AWS S3 bucket.\n",
    "    Parameter:\n",
    "        string path,\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    file_key = path.split('/')[1]\n",
    "    s3.Bucket('crud-bucket-demo').upload_file(Filename = path, Key = file_key)\n",
    "\n",
    "def create_bucket(s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "\n",
    "    s3.create_bucket(Bucket = 'crud-bucket-demo',  CreateBucketConfiguration={'LocationConstraint': 'ap-south-1'})\n",
    "    print(\"Printing all bucket names to verify if - crud-bucket-demo is created:\")\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "\n",
    "def read_bucket(s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "\n",
    "    for obj in s3.Bucket('crud-bucket-demo').objects.all():\n",
    "\n",
    "        print(obj.key)\n",
    "        csv_obj = s3.Bucket('crud-bucket-demo').Object(obj.key).get()\n",
    "        read_df = pd.read_csv(csv_obj['Body'], index_col=0)\n",
    "        print(read_df,\"\\n\")\n",
    "\n",
    "def add_column(obj,new_col,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    address_book_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    address_book_df['MobileNumber'] =  new_col\n",
    "    address_book_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'address_book_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    return address_book_df\n",
    "\n",
    "def add_row(obj,new_row,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    shop_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    shop_df = shop_df.append(new_row, ignore_index = True)\n",
    "    shop_df['ItemID'] = ['ITM001','ITM002','ITM003','ITM004']\n",
    "    shop_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'shop_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    return shop_df\n",
    "\n",
    "def change_value(obj,new_value,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    employee_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    employee_df['EmpID'] = new_value\n",
    "    employee_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'employee_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    return employee_df\n",
    "\n",
    "def delete_bucket(s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "       \n",
    "    Parameter:\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    s3.Bucket('crud-bucket-demo').objects.all().delete()\n",
    "    print('Reading each file from bucket : crud-bucket-demo')\n",
    "\n",
    "    for obj in s3.Bucket('crud-bucket-demo').objects.all():\n",
    "\n",
    "        print(obj.key)\n",
    "        csv_obj = s3.Bucket('crud-bucket-demo').Object(obj.key).get()\n",
    "        read_df = pd.read_csv(csv_obj['Body'], index_col=0)\n",
    "        print(read_df,\"\\n\")\n",
    "\n",
    "    # Delete bucket\n",
    "    s3.Bucket('crud-bucket-demo').delete()\n",
    "    print(\"Printing all bucket names to verify if - crud-bucket-demo is deleted:\")\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    # CRUD operations\n",
    "\n",
    "    # 1. C : CREATE\n",
    "    # 1a. Create Bucket\n",
    "    create_bucket(s3)\n",
    "\n",
    "    # 1b. Reading 3 csv files and loading them to the bucket\n",
    "\n",
    "    path = 'sampleFiles/address_book_csv.csv'\n",
    "    upload_to_bucket(path,s3)\n",
    "\n",
    "    path = 'sampleFiles/employee_csv.csv'\n",
    "    upload_to_bucket(path,s3)\n",
    "\n",
    "    path = 'sampleFiles/shop_csv.csv'\n",
    "    upload_to_bucket(path,s3)\n",
    "\n",
    "    # 2. R : READ\n",
    "    print('\\nReading each file from bucket : crud-bucket-demo')\n",
    "    read_bucket(s3)\n",
    "\n",
    "    # 3. U : UPDATE\n",
    "    # Updating csv files and loading them to bucket\n",
    "\n",
    "    print(\"Adding MobileNumber column to address_book_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('address_book_csv.csv').get()\n",
    "    mobNo = [9012783465,9763214580,8192037465]\n",
    "    new_df = add_column(obj,mobNo,s3)\n",
    "    print(new_df)\n",
    "\n",
    "    #Changing 'EMP003' to 'EMP004' in employee_df\n",
    "    print(\"Changing 'EMP003' to 'EMP004' in employee_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('employee_csv.csv').get()\n",
    "    new_value = ['EMP001','EMP002','EMP004']\n",
    "    new_df = change_value(obj,new_value,s3)\n",
    "    print(new_df)\n",
    "\n",
    "    # Adding new item to shop_df\n",
    "    print(\"Adding new item to shop_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('shop_csv.csv').get()\n",
    "    new_item_dict = {'ItemID':'ITM004', 'ProductName':'Sharpner', 'Price': 10}\n",
    "    new_df = add_row(obj,new_item_dict,s3)\n",
    "    print(new_df)\n",
    "\n",
    "    # 4. D : DELETE\n",
    "    # DELETE Bucket\n",
    "    # Remove all files/objects under bucket and deleting bucket\n",
    "\n",
    "    delete_bucket(s3)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
