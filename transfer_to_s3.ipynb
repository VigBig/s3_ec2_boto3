{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "@Author: Vighnesh Harish Bilgi\n",
    "@Date: 2022-11-02\n",
    "@Last Modified by: Vighnesh Harish Bilgi\n",
    "@Last Modified time: 2022-11-02\n",
    "@Title : Transfer files to CSV \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Upload CSV File to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3', region_name = 'ap-south-1', aws_access_key_id = 'AKIA52DF2WYSM3P6JOML', aws_secret_access_key = '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')\n",
    "    return s3\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    df = pd.read_csv('sampleFiles/iris-dataset.csv')\n",
    "\n",
    "    s3.Bucket('transfer-to-s3').upload_file(Filename = 'sampleFiles/iris-dataset.csv', Key = 'iris-dataset.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Download CSV file from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Industry_aggregation_NZSIOC Industry_code_NZSIOC Industry_name_NZSIOC  \\\n",
      "Year                                                                         \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "2021                     Level 1                99999       All industries   \n",
      "\n",
      "                   Units Variable_code  \\\n",
      "Year                                     \n",
      "2021  Dollars (millions)           H01   \n",
      "2021  Dollars (millions)           H04   \n",
      "2021  Dollars (millions)           H05   \n",
      "2021  Dollars (millions)           H07   \n",
      "2021  Dollars (millions)           H08   \n",
      "\n",
      "                                        Variable_name      Variable_category  \\\n",
      "Year                                                                           \n",
      "2021                                     Total income  Financial performance   \n",
      "2021  Sales, government funding, grants and subsidies  Financial performance   \n",
      "2021                Interest, dividends and donations  Financial performance   \n",
      "2021                             Non-operating income  Financial performance   \n",
      "2021                                Total expenditure  Financial performance   \n",
      "\n",
      "        Value                             Industry_code_ANZSIC06  \n",
      "Year                                                              \n",
      "2021  757,504  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021  674,890  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021   49,593  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021   33,020  ANZSIC06 divisions A-S (excluding classes K633...  \n",
      "2021  654,404  ANZSIC06 divisions A-S (excluding classes K633...  \n"
     ]
    }
   ],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3', region_name = 'ap-south-1', aws_access_key_id = 'AKIA52DF2WYSM3P6JOML', aws_secret_access_key = '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')\n",
    "    return s3\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    obj = s3.Bucket('transfer-to-s3').Object('sampleCSV2.csv').get()\n",
    "\n",
    "    df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    print(df.head(5))\n",
    "\n",
    "    s3.Bucket('transfer-to-s3').download_file(Key = 'sampleCSV2.csv', Filename = 'sampleFiles/sampleCSV2.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload large file to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3', region_name = 'ap-south-1', aws_access_key_id = 'AKIA52DF2WYSM3P6JOML', aws_secret_access_key = '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')\n",
    "    return s3\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    df = pd.read_csv('sampleFiles/iris-dataset.csv')\n",
    "\n",
    "    s3.Bucket('transfer-to-s3').upload_file(Filename = 'sampleFiles/ubuntu-20.04.iso', Key = 'ubuntu-20.04.iso')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CRUD operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading each file from bucket : crud-bucket-demo\n",
      "Printing all bucket names to verify if - crud-bucket-demo is deleted:\n",
      "mumbai-bucket-demo\n",
      "transfer-to-s3\n"
     ]
    }
   ],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3', region_name = 'ap-south-1', aws_access_key_id = 'AKIA52DF2WYSM3P6JOML', aws_secret_access_key = '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')\n",
    "    return s3\n",
    "\n",
    "\n",
    "def create_df(data,csv_name,s3):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        Create a csv out of a dataframe by taking dictionary inputs (i.e. dictionary data) and csv name (i.e. string 'csv_name') and uploading it to AWS S3 bucket.\n",
    "    Parameter:\n",
    "        dictionary data,\n",
    "        string csv_name,\n",
    "        ServiceResource s3\n",
    "    Return:\n",
    "        No values returned.\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "\n",
    "    address_book_df = pd.DataFrame(data)\n",
    "\n",
    "    address_book_df.to_csv(csv_buffer, index= False)\n",
    "\n",
    "    s3.Object('crud-bucket-demo', csv_name).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "def main():\n",
    "\n",
    "    s3 = connect_to_s3()\n",
    "\n",
    "    # CRUD operations\n",
    "\n",
    "    # 1. C : CREATE\n",
    "    # 1a. Create Bucket\n",
    "    s3.create_bucket(Bucket = 'crud-bucket-demo',  CreateBucketConfiguration={'LocationConstraint': 'ap-south-1'})\n",
    "    print(\"Printing all bucket names to verify if - crud-bucket-demo is created:\")\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "\n",
    "    # 1b. Creating 3 Dataframes and loading them to the bucket\n",
    "\n",
    "    contacts = {'Firstname': ['Vighnesh', 'Anoop', 'Carl'],\n",
    "        'Lastname': ['Bilgi', 'Aparajit', 'Pais'],\n",
    "        'City':['Pune','Nagpur','Bengaluru'],\n",
    "        'State':['Maharashtra','Maharashtra','Bengaluru'],\n",
    "        'Zip':[411019,440036,671326],\n",
    "        'Address':['HDFC Colony','Jaitala','Whitefield'],\n",
    "        'Email':['vhbilgi@gmail.com','aa@yahoo.com','cvp@aol.com']}\n",
    "\n",
    "    create_df(contacts,'address_book_csv.csv',s3)\n",
    "\n",
    "    employee = {'EmpID': ['EMP001', 'EMP002', 'EMP003'],\n",
    "        'Firstname': ['George', 'Rahul', 'Priyal'],\n",
    "        'Lastname': ['Smith', 'Kumar', 'Nayak'],\n",
    "        'Role':['DataEngg','SWEngg','SalesEngg'],\n",
    "        'Dept':['IT','IT','Marketing'],\n",
    "        'MobNo':[9049480396,8220858443,987654321]}\n",
    "\n",
    "    create_df(employee,'employee_csv.csv',s3)\n",
    "\n",
    "    items = {'ItemID': ['ITM001', 'ITM002', 'ITM003'],\n",
    "        'ProductName': ['Pepsi', 'Acer', 'Chair'],\n",
    "        'Price': [25, 70000, 500]\n",
    "        }\n",
    "\n",
    "    create_df(items,'shop_csv.csv',s3)\n",
    "\n",
    "    # 2. R : READ\n",
    "    # Reading all csv files from bucket\n",
    "\n",
    "    print('\\nReading each file from bucket : crud-bucket-demo')\n",
    "\n",
    "    for obj in s3.Bucket('crud-bucket-demo').objects.all():\n",
    "\n",
    "        print(obj.key)\n",
    "        csv_obj = s3.Bucket('crud-bucket-demo').Object(obj.key).get()\n",
    "        read_df = pd.read_csv(csv_obj['Body'], index_col=0)\n",
    "        print(read_df,\"\\n\")\n",
    "\n",
    "    # 3. U : UPDATE\n",
    "    # Updating csv files and loading them to bucket\n",
    "\n",
    "    # Adding Mobile Number column to address_book_df\n",
    "    print(\"Adding MobileNumber column to address_book_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('address_book_csv.csv').get()\n",
    "\n",
    "    address_book_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    mobNo = [9012783465,9763214580,8192037465]\n",
    "    address_book_df['MobileNumber'] =  mobNo\n",
    "    print(address_book_df)\n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    address_book_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'address_book_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    #Changing 'EMP003' to 'EMP004' in employee_df\n",
    "    print(\"Changing 'EMP003' to 'EMP004' in employee_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('employee_csv.csv').get()\n",
    "\n",
    "    employee_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    employee_df['EmpID'] = ['EMP001','EMP002','EMP004']\n",
    "    print(employee_df)\n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    employee_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'employee_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    # Adding new item to shop_df\n",
    "    print(\"Adding new item to shop_df\")\n",
    "    obj = s3.Bucket('crud-bucket-demo').Object('shop_csv.csv').get()\n",
    "\n",
    "    shop_df = pd.read_csv(obj['Body'], index_col=0)\n",
    "    new_item_dict = {'ItemID':'ITM004', 'ProductName':'Sharpner', 'Price': 10}\n",
    "    shop_df = shop_df.append(new_item_dict, ignore_index = True)\n",
    "    shop_df['ItemID'] = ['ITM001','ITM002','ITM003','ITM004']\n",
    "    print(shop_df)\n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    shop_df.to_csv(csv_buffer, index= False)\n",
    "    s3.Object('crud-bucket-demo', 'shop_csv.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    # 4. D : DELETE\n",
    "    # DELETE Bucket\n",
    "    # Remove all files/objects under bucket\n",
    "\n",
    "    s3.Bucket('crud-bucket-demo').objects.all().delete()\n",
    "\n",
    "    print('Reading each file from bucket : crud-bucket-demo')\n",
    "\n",
    "    for obj in s3.Bucket('crud-bucket-demo').objects.all():\n",
    "\n",
    "        print(obj.key)\n",
    "        csv_obj = s3.Bucket('crud-bucket-demo').Object(obj.key).get()\n",
    "        read_df = pd.read_csv(csv_obj['Body'], index_col=0)\n",
    "        print(read_df,\"\\n\")\n",
    "\n",
    "    # Delete bucket\n",
    "    s3.Bucket('crud-bucket-demo').delete()\n",
    "    print(\"Printing all bucket names to verify if - crud-bucket-demo is deleted:\")\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
